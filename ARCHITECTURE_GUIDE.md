# ğŸ—ï¸ AI News Scraper - Architecture Guide

## Przewodnik programisty po aplikacji

Ten dokument zawiera szczegÃ³Å‚owÄ… dokumentacjÄ™ architektury systemu AI News Scraper. 
KaÅ¼dy komponent jest opisany z perspektywy jego roli w caÅ‚ym systemie.

---

## ğŸ“‹ Spis treÅ›ci

1. [Architektura ogÃ³lna](#architektura-ogÃ³lna)
2. [System parserÃ³w](#system-parserÃ³w)
3. [Deduplication Engine](#deduplication-engine) 
4. [LangChain Integration](#langchain-integration)
5. [News Orchestration Service](#news-orchestration-service)
6. [Management Commands](#management-commands)

---

## ğŸ¯ Architektura ogÃ³lna

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚â”€â”€â”€â”€â”‚    Parsers       â”‚â”€â”€â”€â”€â”‚  Deduplication  â”‚
â”‚  (RSS/API/Web)  â”‚    â”‚   (34 scrapers)  â”‚    â”‚   (Hash + AI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  News Database  â”‚â—„â”€â”€â”€â”‚ News Orchestratorâ”‚â—„â”€â”€â”€â”‚  LangChain AI   â”‚
â”‚   (Django ORM)  â”‚    â”‚    (Service)     â”‚    â”‚  (Analysis)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Blog Summaries  â”‚â—„â”€â”€â”€â”‚ Summarization    â”‚â—„â”€â”€â”€â”‚   Vector DB     â”‚
â”‚   (Generated)   â”‚    â”‚   (AI-powered)   â”‚    â”‚   (Qdrant)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ System parserÃ³w

### Struktura folderÃ³w
```
src/parsers/
â”œâ”€â”€ base.py              # Klasy bazowe i struktury danych
â”œâ”€â”€ factory.py           # Auto-discovery i Factory Pattern  
â”œâ”€â”€ rss_base.py          # Bazowy scraper dla RSS
â”œâ”€â”€ openai_blog_scraper.py    # Parser dla OpenAI Blog
â”œâ”€â”€ hackernews_scraper.py     # Parser dla Hacker News API
â”œâ”€â”€ ... (32+ wiÄ™cej parserÃ³w)
```

### Kluczowe klasy:

#### `NewsArticleData` (base.py)
GÅ‚Ã³wna struktura danych reprezentujÄ…ca artykuÅ‚ newsowy.

**Rola:** Standardowy interfejs miÄ™dzy wszystkimi komponentami systemu.
**Wykorzystanie:** Parsery â†’ Deduplication â†’ Database â†’ Summarization

#### `BaseScraper` (base.py) 
Abstrakcyjna klasa bazowa implementujÄ…ca Template Method Pattern.

**Rola:** Zapewnia wspÃ³lnÄ… funkcjonalnoÅ›Ä‡ (HTTP session, date parsing, text cleaning)
**Implementacje:** RSSFeedScraper, HackerNewsScraper, Reddit scrapers

#### `ScraperFactory` (factory.py)
Auto-discovery system z Factory Pattern.

**Mechanizm:**
1. Skanuje folder `parsers/` szukajÄ…c plikÃ³w `*_scraper.py`
2. Importuje dynamicznie kaÅ¼dy moduÅ‚
3. Znajduje klasy dziedziczÄ…ce po `BaseScraper`
4. Generuje user-friendly nazwy: `"OpenAIBlogScraper"` â†’ `"openai_blog"`
5. Przechowuje w registry: `Dict[str, Type[BaseScraper]]`

---

## ğŸ” Deduplication Engine

### Dwa poziomy deduplikacji:

#### 1. **ContentHashDeduplicator** - Exact matches
```python
# SHA256 hash z peÅ‚nej treÅ›ci artykuÅ‚u
content_hash = hashlib.sha256(content.encode('utf-8')).hexdigest()

# Check w database
if NewsArticle.objects.filter(content_hash=content_hash).exists():
    return True  # Exact duplicate
```

#### 2. **VectorDeduplicator** - Semantic similarity
```python  
# OpenAI embeddings (1536-dimensional vectors)
embedding = openai.embeddings.create(input=content, model="text-embedding-3-small")

# Qdrant vector search z 85% threshold
similar = qdrant_client.search(
    collection_name="news_articles",
    query_vector=embedding,
    limit=1,
    score_threshold=0.85
)
```

#### `DuplicationService` - Orchestrator
ÅÄ…czy oba approaches:
1. **Fast path:** Exact hash matching (najszybsze)
2. **Smart path:** Semantic similarity (AI-powered)
3. **Storage:** Dodaje unique articles do vector index

---

## ğŸ¤– LangChain Integration

### Komponenty AI w systemie:

#### `NewsAnalyzer` (langchain_chains.py)
**Cel:** Strukturalna analiza artykuÅ‚Ã³w z AI
**Input:** NewsArticleData  
**Output:** Structured Pydantic models z kategoriami, importance scores, key topics

```python
# LCEL chain pattern
analysis_chain = analysis_prompt | llm | output_parser

# Structured output
class NewsAnalysisResult(BaseModel):
    key_topics: List[str]
    importance_score: float  # 0.0-1.0
    category: str           # "AI", "Tech", "Business"
    summary: str
```

#### `BlogGenerator` (langchain_chains.py)
**Cel:** Generowanie blog posts z multiple articles
**Mechanizm:** Map-reduce pattern dla duÅ¼ych zbiorÃ³w artykuÅ‚Ã³w

#### `NewsProcessingAgent` (langchain_chains.py)  
**Cel:** Conversational AI agent z tools
**Tools:** Search articles, get stats, analyze trends
**Architecture:** OpenAI Functions + LangChain agents

---

## ğŸ¼ News Orchestration Service

### `NewsOrchestrationService` (news_service.py)

Jest to gÅ‚Ã³wny koordinator caÅ‚ego systemu. ÅÄ…czy wszystkie komponenty:

```python
class NewsOrchestrationService:
    def __init__(self):
        self.duplication_service = DuplicationService()      # Deduplication
        self.blog_summary_service = BlogSummaryService()     # AI Summarization  
        self.langchain_orchestrator = LangChainOrchestrator() # AI Analysis
```

#### GÅ‚Ã³wne workflow:

1. **`scrape_all_sources()`** - Orchestrates scraping z wszystkich parserÃ³w
2. **`scrape_single_source()`** - Single source z deduplication
3. **`run_full_pipeline()`** - Complete end-to-end process
4. **`create_intelligent_blog_summary()`** - AI-powered blog generation

#### Pipeline flow:
```
Sources â†’ Scrapers â†’ Raw Articles â†’ Deduplication â†’ Unique Articles â†’ Database
                                      â†“
Blog Summaries â† AI Summarization â† LangChain Analysis â† Vector Index
```

---

## ğŸ’» Management Commands  

### `scrape_news` command
**Location:** `management/commands/scrape_news.py`

**Usage:**
```bash
python manage.py scrape_news --all                    # Scrape wszystko
python manage.py scrape_news --source openai_blog     # Specific source
python manage.py scrape_news --list-sources           # List all parsers
python manage.py scrape_news --all --generate-summary # Z AI summary
```

### `langchain_analysis` command  
**Location:** `management/commands/langchain_analysis.py`

**Usage:**
```bash
python manage.py langchain_analysis --query "What are the latest AI trends?"
python manage.py langchain_analysis --search "machine learning" --limit 5
python manage.py langchain_analysis --analyze --topic "AI News" 
python manage.py langchain_analysis --intelligent-summary --topic "Tech"
```

---

## ğŸ”„ Data Flow Diagram

```
â”Œâ”€ RSS Feeds â”€â”  â”Œâ”€ API Sources â”€â”  â”Œâ”€ Web Scraping â”€â”
â”‚   34 feeds  â”‚  â”‚  Hacker News  â”‚  â”‚   Reddit etc   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  ScraperFactory  â”‚ â—„â”€â”€ Auto-discovery
              â”‚   (34 parsers)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ NewsArticleData  â”‚ â—„â”€â”€ Standardized format
              â”‚   (title, url,   â”‚
              â”‚  content, date)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  DuplicationService     â”‚
          â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
          â”‚ â”‚SHA256   â”‚ â”‚Vector   â”‚ â”‚ â—„â”€â”€ Dual deduplication
          â”‚ â”‚Hash     â”‚ â”‚Search   â”‚ â”‚
          â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                    â–¼         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ NewsArticle â”‚   â”‚ Vector Index â”‚
          â”‚ (Database)  â”‚   â”‚  (Qdrant)    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ LangChain Analysis   â”‚ â—„â”€â”€ AI processing
              â”‚ - Topic extraction   â”‚
              â”‚ - Importance scoring â”‚  
              â”‚ - Summarization     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Blog Summary   â”‚ â—„â”€â”€ Generated content
              â”‚  (AI-powered)    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª Testing Architecture

### Test Structure (mirrors src/):
```
tests/
â”œâ”€â”€ base.py                 # Test utilities i mocks
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ test_base.py        # BaseScraper tests
â”‚   â”œâ”€â”€ test_factory.py     # Auto-discovery tests
â”‚   â””â”€â”€ test_specific_scrapers.py
â”œâ”€â”€ test_deduplication.py   # Hash + Vector tests
â”œâ”€â”€ test_langchain_chains.py # AI components tests
â”œâ”€â”€ test_news_service.py    # Orchestration tests
â””â”€â”€ management/commands/    # Command tests
```

### Kluczowe wzorce testowe:
- **Comprehensive mocking:** OpenAI API, Qdrant, RSS feeds
- **Factory testing:** Auto-discovery i error handling
- **Integration tests:** End-to-end pipeline testing
- **Command testing:** CLI interface testing

---

## ğŸš€ Deployment Considerations

### Required Services:
1. **Qdrant Vector Database** - Port 6333
2. **OpenAI API Access** - API key required
3. **Django Database** - SQLite/PostgreSQL
4. **Python 3.12+** - Latest optimizations

### Environment Variables:
```bash
OPENAI_API_KEY=your-key-here          # Required
LANGCHAIN_API_KEY=langsmith-key       # Optional (monitoring)
QDRANT_HOST=localhost                 # Vector DB
QDRANT_PORT=6333                      # Vector DB port
```

### Scaling Points:
- **Parser count:** Auto-discovery scales to 100+ sources
- **Vector similarity:** Qdrant handles millions of articles  
- **AI processing:** Rate-limited by OpenAI quotas
- **Database:** Standard Django ORM scaling patterns

---

*Ten przewodnik zawiera kluczowe informacje architektury. SzczegÃ³Å‚owe docstringi w kodzie zawierajÄ… implementation details dla kaÅ¼dego komponentu.*